# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

commands:
  destroy_environment:
    parameters:
      when_to_run:
        type: string
        default: "on_fail"
    steps:
      - run:
          name: Destroy the created environment
          command: |
            aws cloudformation delete-stack --stack-name prod-${CIRCLE_WORKFLOW_ID}
          when: << parameters.when_to_run >>
jobs:
  create_infrastructure:
    docker:
      - image: amazon/aws-cli:latest
    steps:
      - checkout
      - run:
          name: "install required packages"
          command: yum install -y tar gzip
      - run:
          name: "Ensure Backend infrastructure exists"
          command: |
            aws cloudformation deploy \
            --stack-name prod-${CIRCLE_WORKFLOW_ID} \
            --template-file aws-template.yml

      - run:
          command: |
            echo [ec2] > ~/inventory.txt
      - run:
          name: check ec2 istance ip
          command: |
            aws ec2 describe-instances \
            --query 'Reservations[*].Instances[*].PublicIpAddress' \
            --filters "Name=tag:Project,Values=udacity" \
            --output text >> ~/inventory.txt
      - run:
          command: |
            cat ~/inventory.txt

      - persist_to_workspace:
          root: ~/
          paths:
            - inventory.txt

  configure_infrastructure:
    docker:
      - image: python:3.7-alpine3.11
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["44:cb:83:26:de:39:5c:97:bc:30:16:87:aa:3f:11:49"]
      - attach_workspace:
          at: ~/
      - run:
          name: "Install dependencies"
          command: |
            apk add --update ansible
      - run:
          name: "Configure server"
          command: |
            ansible-playbook -i ~/inventory.txt playbook.yml

  smoke_test:
    docker:
      - image: alpine:latest
    steps:
      - run: apk add -update curl
      - run:
          name: "smoke test"
          command: |
            URL="https://blog.udacity.com/"
            if curl -s --head ${URL}
            then
              return 0
            else
              return 1
            fi

  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli:latest
    steps:
      - checkout
      - run:
          name: create s3 bucket
          command: |
            aws cloudformation deploy \
              --template-file bucket.yml \
              --stack-name prod-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides NAME=${CIRCLE_WORKFLOW_ID:0:7}
      - run:
          name: copy index.html to bucket
          command: |
            aws s3 cp index.html s3://${CIRCLE_WORKFLOW_ID:0:7}/

  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli:latest
    steps:
      - run:
          name: "install required packages"
          command: yum install -y tar gzip
      - run:
          name: Wich pipeline done last successfull production
          command: |
            aws cloudformation \
              list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
              --no-paginate --output text > ~/pipelineId.txt
      - run: cat ~/pipelineId.txt
      - persist_to_workspace:
          root: ~/
          paths:
            - pipelineId.txt
  promote_to_production:
    docker:
      - image: amazon/aws-cli:latest
    steps:
      - checkout
      - run:
          name: promotion to production
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro \
            --parameter-overrides PipelineID="${CIRCLE_WORKFLOW_ID:0:7}"

  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli:latest
    steps:
      - run:
          name: "install required packages"
          command: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run: OldPipelineId=$(cat ~/pipelineId.txt)
      - run: echo ${OldPipelineId}
      - run: aws s3 rm "s3://${OldPipelineID}" --recursive
      - run: cloudformation delete-stack --stack-name "prod-${OldPipelineID}"

workflows:
  my_workflow:
    # Run the run job in its own container
    jobs:
      # - create_infrastructure
      # - configure_infrastructure:
      #     requires:
      #       - create_infrastructure
      # - smoke_test:
      #     requires:
      #       - configure_infrastructure
      # - create_and_deploy_front_end
      # - promote_to_production:
      #     requires:
      #       - create_and_deploy_front_end
      - get_last_deployment_id
        # requires:
        #   - promote_to_production
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
